{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import MDS, TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd\n",
    "from gb_writer import GlyphboardWriter\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from typing import Any\n",
    "# import spacy\n",
    "# from spacy.lang.de.stop_words import STOP_WORDS\n",
    "\n",
    "\n",
    "# nlp = spacy.load('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTestData():\n",
    "    with open(\"test_data.json\", \"r\") as read_file:\n",
    "        test_data = json.load(read_file)\n",
    "    test_texts = []\n",
    "    test_labels = []\n",
    "    for doc in test_data:\n",
    "    #     # only use confident labels\n",
    "         if (doc[\"features\"][\"1\"][\"4\"] > 0.5):\n",
    "            test_labels.append(1)\n",
    "            test_texts.append(doc[\"values\"][\"7\"])\n",
    "         else:\n",
    "             test_labels.append(0)\n",
    "             test_texts.append(doc[\"values\"][\"7\"])\n",
    "    return pd.DataFrame({'text': test_texts, 'label': test_labels})\n",
    "\n",
    "def train(train_data, test_data, algo: Any) -> dict:\n",
    "    # clean_data = [preprocessText(text) for text in data]\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        # ('nlp', preprocessText())\n",
    "        # ('clf', LogisticRegression()),\n",
    "        # ('clf', MultinomialNB()),\n",
    "        ('clf', algo),\n",
    "    ])\n",
    "    text_clf.fit(train_data.text, train_data.label)\n",
    "    # text_clf.fit(clean_data, labels)\n",
    "    predicted = text_clf.predict(test_data.text)\n",
    "    # print(dataframe.prediction.value_counts())\n",
    "    # print(metrics.classification_report(test_labels, predicted))\n",
    "    addHistory(metrics.f1_score(test_data.label, predicted))\n",
    "    result = {\n",
    "        # 'prediction': predicted.toList(),\n",
    "        # 'accuracy': metrics.accuracy_score(test_labels, predicted),\n",
    "        'precision': metrics.precision_score(test_data.label, predicted),\n",
    "        'recall': metrics.recall_score(test_data.label, predicted),\n",
    "        'f1': metrics.f1_score(test_data.label, predicted),\n",
    "        'f1_history': getHistory()\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def getHistory():\n",
    "    history = []\n",
    "    with open(\n",
    "            \"mlbackend/metrics.csv\", \"r\", encoding=\"utf8\") as file:\n",
    "        reader = csv.reader(file, delimiter=';')\n",
    "        for line in reader:\n",
    "            history.append(line[0])\n",
    "        file.close()\n",
    "    return history\n",
    "\n",
    "def addHistory(metrics):\n",
    "    with open(\n",
    "            \"mlbackend/metrics.csv\", \"a\",  newline=\"\", encoding=\"utf8\") as file:\n",
    "        writer = csv.writer(file, delimiter=';')\n",
    "        writer.writerow([str(metrics)])\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyDR(tfidf, labels):\n",
    "    # mds = MDS(n_components=2, random_state=1).fit_transform(tfidf.toarray())\n",
    "    lsi = TruncatedSVD(n_components=100, random_state=1).fit_transform(tfidf.toarray())\n",
    "    # mds = MDS(n_components=2, random_state=1).fit_transform(lsi)\n",
    "    with_labels = np.hstack((lsi, labels))\n",
    "    mds = TSNE(n_components=2, random_state=1).fit_transform(with_labels)\n",
    "    df = pd.DataFrame(columns=['x', 'y'])\n",
    "    df['x'] = mds[:, 0]\n",
    "    df['y'] = mds[:, 1]\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lsi = TruncatedSVD(n_components=100, random_state=1).fit_transform(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying DR...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-a6efa88df8fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Applying DR...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mDR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapplyDR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mDR\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-b0264b377cc2>\u001b[0m in \u001b[0;36mapplyDR\u001b[1;34m(tfidf, labels)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlsi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# mds = MDS(n_components=2, random_state=1).fit_transform(lsi)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mwith_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlsi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ducanh.trinh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "data = getTestData()\n",
    "vec = TfidfVectorizer()\n",
    "tfidf = vec.fit_transform(data.text)\n",
    "print('Applying DR...')\n",
    "DR = applyDR(tfidf, labels=data.label)\n",
    "\n",
    "DR *= 500\n",
    "# DR.x *= 500\n",
    "# DR.y *= 500\n",
    "\n",
    "print(DR)\n",
    "\n",
    "writer = GlyphboardWriter('test_name')\n",
    "\n",
    "# DR *= 2\n",
    "print('Writing positions...')    \n",
    "writer.write_position(DR, 'mds')\n",
    "del DR\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
