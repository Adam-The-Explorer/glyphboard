{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ducanh.trinh\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.manifold import MDS, TSNE, LocallyLinearEmbedding, Isomap\n",
    "from MulticoreTSNE import MulticoreTSNE\n",
    "from sklearn.decomposition import TruncatedSVD, PCA, KernelPCA, SparsePCA\n",
    "import umap\n",
    "from scipy.sparse import vstack\n",
    "import pandas as pd\n",
    "from gb_writer import GlyphboardWriter\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from typing import Any\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import spacy\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "\n",
    "\n",
    "nlp = spacy.load('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "SGD = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3,\n",
    "                    random_state=42, max_iter=5, tol=None)\n",
    "MNB = MultinomialNB()\n",
    "LR = LogisticRegression()\n",
    "SVC = LinearSVC()\n",
    "KNC = KNeighborsClassifier()\n",
    "NC = NearestCentroid()\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "vec = TfidfVectorizer(strip_accents='ascii', max_df=0.5, sublinear_tf=True)\n",
    "SPLICE_POINT = 800\n",
    "UNLABELED_VALUE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    print('Updating JSON...')\n",
    "    updateDatasetJson()\n",
    "    # print('Cleaning Texts...')\n",
    "    # cleanupTexts()\n",
    "    print('Done')\n",
    "\n",
    "def mockInit():\n",
    "    texts = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    peer_labels = []\n",
    "    with open(\"test_data.json\", \"r\") as read_file:\n",
    "        LC_data = json.load(read_file)\n",
    "\n",
    "    for doc in LC_data:\n",
    "        ids.append(doc['id'])\n",
    "        texts.append(doc[\"values\"][\"7\"])\n",
    "        peer_labels.append(doc[\"features\"][\"1\"][\"4\"])\n",
    "        # simulate all as labeled (for test_data)\n",
    "        if (doc[\"features\"][\"1\"][\"4\"] > 0.5):\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'text': texts,\n",
    "        'label': labels,\n",
    "        'peer_label': peer_labels,\n",
    "        'score': [0] * len(LC_data),\n",
    "        'isLabeled': [0]  * len(LC_data)\n",
    "    })\n",
    "   \n",
    "    test_data = df[SPLICE_POINT+1:]\n",
    "    saveData(test_data, 'test_data')\n",
    "    # test_data.to_csv('test_data.csv', sep=\";\", encoding=\"utf8\", index=False)\n",
    "    data_with_scores = getSelectionScores(rest_data=df)\n",
    "    saveData(data_with_scores)\n",
    "    resetTrainData()\n",
    "    \n",
    "    # data_with_scores.to_csv('data.csv', sep=\";\", encoding=\"utf8\", index=False)\n",
    "    # resetTrainData()\n",
    "\n",
    "def loadData(name = 'data'):\n",
    "    return pd.read_csv('{}.csv'.format(name), sep=\";\", encoding=\"utf8\")\n",
    "\n",
    "def saveData(data, name = 'data'):\n",
    "    data.to_csv('{}.csv'.format(name), sep=\";\", encoding=\"utf8\", index=False)\n",
    "\n",
    "def handleNewAnswer(answer):\n",
    "    newAnswer = {\n",
    "        'text': answer['text'],\n",
    "        'docId': answer['documentId'],\n",
    "        'label': int(answer['answer']),\n",
    "        'question': answer['questionId']\n",
    "    }\n",
    "    train_data = getTrainData()\n",
    "\n",
    "    test_data = getTestData()\n",
    "    \n",
    "    data = updateDataWithLabel(loadData(), newAnswer['docId'], newAnswer['label'])\n",
    "    if len(train_data) > 3:\n",
    "        # tfidf = vec.fit_transform(data.text)        \n",
    "        # positions = applyDR(tfidf, withPreviousPos=False, labels=data.label)\n",
    "        # writer = GlyphboardWriter('test_name')\n",
    "        # position_response = writer.write_position(positions=positions, algorithm='umap')\n",
    "        train_result = train(train_data, test_data, SGD)\n",
    "        return {\n",
    "            # 'positions': position_response,\n",
    "            'train_result': train_result\n",
    "        }\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def handleCompleteUpdate():\n",
    "    data = loadData()\n",
    "    # updateDatasetJson()\n",
    "    tfidf = vec.fit_transform(data.text)\n",
    "    positions = applyDR(tfidf, withPreviousPos=True, labels=data.label)\n",
    "    writer = GlyphboardWriter('test_name')\n",
    "    position_response = writer.write_position(positions=positions, algorithm='umap')\n",
    "    return position_response\n",
    "\n",
    "def updateDatasetJson():\n",
    "    with open(\"test_data.json\", \"r\") as read_file:\n",
    "        LC_data = json.load(read_file)\n",
    "        \n",
    "    data = loadData()\n",
    "\n",
    "    for doc in LC_data:\n",
    "        doc['features']['1']['31'] = int(data.loc[data['id'] == doc['id']].isLabeled.values[0])\n",
    "        doc['values']['31'] = int(data.loc[data['id'] == doc['id']].isLabeled.values[0])\n",
    "        doc['features']['1']['32'] = data.loc[data['id'] == doc['id']].score.values[0]\n",
    "        doc['values']['32'] = data.loc[data['id'] == doc['id']].score.values[0]\n",
    "        doc['features']['1']['33'] = int(data.loc[data['id'] == doc['id']].label.values[0])\n",
    "        doc['values']['33'] = int(data.loc[data['id'] == doc['id']].label.values[0])\n",
    "\n",
    "    with open(\"../backend/data/mainTfIdf/mainTfIdf.05112018.feature.json\", \"w\") as f:\n",
    "            json.dump(LC_data, f)\n",
    "    \n",
    "    return 'Done'\n",
    "\n",
    "# def updateSingleData(id: number, label, isLabeled):\n",
    "#     data = loadData()\n",
    "#     json = \n",
    "\n",
    "def updateDataWithLabel(data, docId, label):\n",
    "    print('before', data.loc[data['id'] == docId])\n",
    "    data.loc[data['id'] == docId, 'label'] = int(label)\n",
    "    data.loc[data['id'] == docId, 'isLabeled'] = 1\n",
    "    print('after', data.loc[data['id'] == docId])\n",
    "    saveData(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def createMetrics(algo):\n",
    "    test_data = getTestData()\n",
    "    train_data_df = getTrainData()\n",
    "    train_data_df.label = train_data_df.label.astype(int)\n",
    "    met = []\n",
    "    # Create stepwise metrics algo, simulating a history\n",
    "    for number in range(30, len(train_data_df)):\n",
    "        train_data_iteration = train_data_df.head(number)\n",
    "        met.append(train(train_data_iteration, test_data, algo=algo))\n",
    "    return pd.DataFrame(met)\n",
    "\n",
    "\n",
    "def train(train_data, test_data, algo: Any) -> dict:\n",
    "    text_clf = Pipeline([\n",
    "        # ('vect', CountVectorizer()),\n",
    "        ('tfidf', vec),\n",
    "        ('clf', algo),\n",
    "    ])\n",
    "    text_clf.fit(train_data.text, train_data.label)\n",
    "    predicted = text_clf.predict(test_data.text)\n",
    "    addHistory(metrics.f1_score(test_data.label, predicted))\n",
    "    result = {\n",
    "        'precision': metrics.precision_score(test_data.label, predicted),\n",
    "        'recall': metrics.recall_score(test_data.label, predicted),\n",
    "        'f1': metrics.f1_score(test_data.label, predicted),\n",
    "        'f1_history': getHistory()\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def getTrainData():\n",
    "    data = loadData()\n",
    "    return data.loc[data['isLabeled'] == 1]\n",
    "\n",
    "def getTestData():\n",
    "    return pd.read_csv('test_data.csv', delimiter=';', encoding=\"utf8\")\n",
    "\n",
    "def resetTrainData():\n",
    "    data = loadData()\n",
    "    data.loc[:, 'label'] = UNLABELED_VALUE\n",
    "    data.loc[:, 'isLabeled'] = 0\n",
    "    saveData(data)\n",
    "\n",
    "def cleanupTexts():\n",
    "    data = loadData()\n",
    "    for idx, text in enumerate(data.text):\n",
    "        data.loc[idx, 'text'] = preprocessText(text)\n",
    "        \n",
    "    saveData(data)\n",
    "\n",
    "def mockTraining(amount):\n",
    "    data = loadData()\n",
    "    for i in range(amount):\n",
    "        data.loc[i, 'isLabeled'] = 1\n",
    "        if data.loc[i].peer_label > 0.5:\n",
    "            data.loc[i, 'label'] = 1\n",
    "        else:\n",
    "            data.loc[i, 'label'] = 0        \n",
    "    saveData(data)\n",
    "\n",
    "def simulateTraining(iterations):\n",
    "    test_data = getTestData()\n",
    "    mockTraining(iterations)\n",
    "    train_data = getTrainData()\n",
    "    train(train_data, test_data, SGD)\n",
    "\n",
    "def getHistory():\n",
    "    history = []\n",
    "    with open(\n",
    "            \"metrics.csv\", \"r\", encoding=\"utf8\") as file:\n",
    "        reader = csv.reader(file, delimiter=';')\n",
    "        for line in reader:\n",
    "            history.append(line[0])\n",
    "        file.close()\n",
    "    return history\n",
    "\n",
    "\n",
    "def addHistory(metrics):\n",
    "    with open(\n",
    "            \"metrics.csv\", \"a\",  newline=\"\", encoding=\"utf8\") as file:\n",
    "        writer = csv.writer(file, delimiter=';')\n",
    "        writer.writerow([str(metrics)])\n",
    "        file.close()\n",
    "\n",
    "def getCurrentScore() -> int:\n",
    "    return getHistory().pop()\n",
    "\n",
    "def applyDR(tfidf, labels = [], withPreviousPos = True, factor = 1):    \n",
    "    # pre_computed = TruncatedSVD(n_components=100, random_state=1).fit_transform(tfidf.toarray())\n",
    "    # LABEL_IMPACT = 0\n",
    "    if withPreviousPos:        \n",
    "        previousPositions = loadData('previousPositions').values\n",
    "    else:\n",
    "        previousPositions = 'spectral'\n",
    "    labels_arr = np.asarray(labels)\n",
    "    labels_arr = labels_arr.reshape(len(labels_arr), 1)\n",
    "    # with_labels = np.hstack((tfidf.toarray(), labels_arr))\n",
    "    computed_coords = umap.UMAP(init=previousPositions,min_dist=0.8, random_state=1, learning_rate=0.5).fit(tfidf.toarray(), y=labels_arr)\n",
    "    computed_coords = computed_coords.embedding_\n",
    "    saveData(pd.DataFrame(computed_coords), 'previousPositions')\n",
    "    computed_coords *= factor    \n",
    "    # computed_coords = MulticoreTSNE(n_jobs=4, random_state=1).fit_transform(with_labels)\n",
    "    df = pd.DataFrame(columns=['x', 'y'])\n",
    "    df['x'] = computed_coords[:, 0]\n",
    "    df['y'] = computed_coords[:, 1]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# def resetPositions():\n",
    "\n",
    "\n",
    "def preprocessText(text: str) -> str:\n",
    "    # print('Original: ', text)\n",
    "    doc = nlp(text)\n",
    "    # Remove Stop Words and get Lemmas\n",
    "    return ' '.join([token.lemma_ for token in doc if not token.is_stop])\n",
    "    # for word in doc:\n",
    "    #     if word.is_stop == True:\n",
    "    #         print('Stop %s', word)\n",
    "    # print(word.lemma_)\n",
    "\n",
    "#             # Get NER\n",
    "#     for ent in doc.ents:\n",
    "#         print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "def getSelectionScores(clf = MNB, rest_data = loadData(), train_data = getTestData()): \n",
    "    text_clf = Pipeline([\n",
    "        # ('vect', CountVectorizer()),\n",
    "        ('tfidf', vec),\n",
    "        ('clf', clf),\n",
    "    ])\n",
    "    text_clf.fit(train_data.text, train_data.label)\n",
    "    prs = text_clf.predict_proba(rest_data.text) \n",
    "    result_pos = [1-2*abs(x[1]-0.5)  for x in prs]\n",
    "    rest_data['score'] = result_pos\n",
    "    return rest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateDatasetJson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mockTraining(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>isLabeled</th>\n",
       "      <th>label</th>\n",
       "      <th>peer_label</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>295</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.995374</td>\n",
       "      <td>GARDENS END Sommerspecial - Die Rockband Garde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.497636</td>\n",
       "      <td>Sand in der Ritze #2 Nach einer gemütlichen un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.684377</td>\n",
       "      <td>The next Gamestorm Cocktail! Der Gamestorm bek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.991680</td>\n",
       "      <td>Klassisches Konzert Costabell Romantischer Kla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>803</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>0.927309</td>\n",
       "      <td>Sommerakademie 2014 \"Mystik  und Alltag im int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>948</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.956348</td>\n",
       "      <td>Jazz im Weingut Pix Jazz im Weingut Pix\\r\\r\\r\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  isLabeled  label  peer_label     score  \\\n",
       "294  295          1      1     1.00000  0.995374   \n",
       "398  399          1      1     0.00000  0.497636   \n",
       "540  541          1      0     0.00000  0.684377   \n",
       "666  667          1      1     1.00000  0.991680   \n",
       "802  803          1      0     0.68750  0.927309   \n",
       "947  948          1      1     0.96875  0.956348   \n",
       "\n",
       "                                                  text  \n",
       "294  GARDENS END Sommerspecial - Die Rockband Garde...  \n",
       "398  Sand in der Ritze #2 Nach einer gemütlichen un...  \n",
       "540  The next Gamestorm Cocktail! Der Gamestorm bek...  \n",
       "666  Klassisches Konzert Costabell Romantischer Kla...  \n",
       "802  Sommerakademie 2014 \"Mystik  und Alltag im int...  \n",
       "947  Jazz im Weingut Pix Jazz im Weingut Pix\\r\\r\\r\\...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTrainData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cleanupTexts()\n",
    "data = loadData()\n",
    "tfidf = vec.fit_transform(data.text)\n",
    "positions = applyDR(tfidf, labels=np.empty(1118), withPreviousPos=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'backend/data/mainTfIdf/mainTfIdf.05112018.position.umap.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-b266d0d9f847>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGlyphboardWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mposition_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpositions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'umap'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\projects\\glyphboard\\mlbackend\\gb_writer.py\u001b[0m in \u001b[0;36mwrite_position\u001b[1;34m(self, positions, algorithm)\u001b[0m\n\u001b[0;32m     55\u001b[0m                 }\n\u001b[0;32m     56\u001b[0m             })\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'backend/data/mainTfIdf/mainTfIdf.05112018.position.umap.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'backend/data/mainTfIdf/mainTfIdf.05112018.position.umap.json'"
     ]
    }
   ],
   "source": [
    "writer = GlyphboardWriter('test_name')\n",
    "position_response = writer.write_position(positions=positions, algorithm='umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mock everything for demo\n",
    "resetTrainData()\n",
    "mockTraining(1100)\n",
    "getSelectionScores()\n",
    "updateDatasetJson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-1.0474\tanmeldung      \t\t4.3388\tmusik          \n",
      "\t-0.9391\tevents         \t\t3.8886\tdj             \n",
      "\t-0.9210\t17             \t\t2.7387\tkonzert        \n",
      "\t-0.8045\tglucksrad      \t\t2.1002\tlive           \n",
      "\t-0.6816\tvortrag        \t\t2.0477\trock           \n",
      "\t-0.6793\tmontag         \t\t1.9709\tbinden         \n",
      "\t-0.6669\tstammtisch     \t\t1.9259\tkaraoke        \n",
      "\t-0.6592\ttreffen        \t\t1.7731\tmusikalisch    \n",
      "\t-0.6436\tlesung         \t\t1.6984\tmusic          \n",
      "\t-0.6312\trumanischer    \t\t1.6058\tsong           \n",
      "\t-0.6162\tmensch         \t\t1.4400\tjazz           \n",
      "\t-0.6008\tweihnachtsfeier\t\t1.4394\tmusiker        \n",
      "\t-0.6001\twas            \t\t1.3633\tweihnachtskonzert\n",
      "\t-0.5967\tkurz           \t\t1.3421\thop            \n",
      "\t-0.5935\tfuhrung        \t\t1.3308\thit            \n",
      "\t-0.5931\t12             \t\t1.3110\teintritt       \n",
      "\t-0.5906\tspieletag      \t\t1.3071\tklavier        \n",
      "\t-0.5879\tlesen          \t\t1.2561\tband           \n",
      "\t-0.5830\tbrauchen       \t\t1.2235\tspielen        \n",
      "\t-0.5812\tjed            \t\t1.2110\tbeats          \n"
     ]
    }
   ],
   "source": [
    "# Check important features of classification\n",
    "# cleanupTexts()\n",
    "train_data = getTrainData()\n",
    "tfidf = vec.fit_transform(train_data.text)\n",
    "clf = SGD\n",
    "clf.fit(tfidf, train_data.label)\n",
    "feature_names = vec.get_feature_names()\n",
    "coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "top = zip(coefs_with_fns[:20], coefs_with_fns[:-(20 + 1):-1])\n",
    "for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "    print ('\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s' % (coef_1, fn_1, coef_2, fn_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'318'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2441\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2442\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5280)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5126)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20523)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20477)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '318'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-9cd134639df2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# cleanupTexts()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'318'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1964\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1645\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2442\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2444\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5280)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5126)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20523)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20477)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '318'"
     ]
    }
   ],
   "source": [
    "# cleanupTexts()\n",
    "data[].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetTrainData()\n",
    "# mockTraining(500)\n",
    "# SGD_met = createMetrics(SGD)\n",
    "# MNB_met = createMetrics(MNB)\n",
    "# KNC_met = createMetrics(KNC)\n",
    "# NC_met = createMetrics(NC)\n",
    "RFC_met = createMetrics(RFC)\n",
    "# getTrainData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SGD_met.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MNB_met.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNC_met.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NC_met.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_met.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
